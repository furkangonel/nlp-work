import nltk   # natural language toolkitnltk.download("punkt_tab")  # metni kelime ve cumle bazinda tokenlera ayirabilmek için gereklitext = "Hello, World! How are you? Hello, hi ..."# kelime tokenizasyonu: word_tokenize: metni kelimelere ayirir.# noktalama isaretleri ve bosluklarinayr, birer token olarak elde edilecektir.word_tokens = nltk.word_tokenize(text)# cumle tokenizasyonu: sent_tokenize: metni cümlelere ayirir. Her bir cumle token olur.sentence_tokenize = nltk.sent_tokenize(text)